# Реализация ETL в Airflow

### Описание
Этапы ETL пайплайна - формирование и получение инкремента данных через API, загрузка в staging-слой БД, обновление витрин данных автоматизированы с помощью Airflow с соблюдением принципа идемпотентности.

### Структура репозитория
1. Папка `dags` содержит DAG's Airflow.
    * Папка `sql` содержит SQL-скрипты загрузки инкремента в БД.

## Технические детали
### Как запустить контейнер
Запустите локально команду:

```
docker run -d -p 3000:3000 -p 15432:5432 --name=de-project-sprint-3-server sindb/project-sprint-3:latest
```

После того как запустится контейнер, у вас будут доступны:
1. Airflow
2. VSCode
3. CloudBeaver
4. PostgreSQL

Airflow доступен по ссылке: `http://localhost:3000/airflow`

Для действий над БД вы можете использовать любой из инструментов:
- Утилиту командной строки `psql`. Подключиться к нужной БД можно командой: `psql postgresql://jovyan:jovyan@localhost:5432/de`.
- Сервис DBeaver. Чтобы использовать его, перейдите по URI `/cloudbeaver/` и нажмите на кнопку `SQL` в верхнем меню. Тогда откроется страница для написания и выполнения запросов.
- CloudBeaver иногда может перенаправить вас на адрес без порта, например, `http://localhost/cloudbeaver` вместо `http://localhost:3000/cloudbeaver`. Исправьте это, вручную дописав порт
- Metabase также позволяет выполнять произвольные запросы на чтение.

В контейнере запущена база данных *PostgreSQL*:
- логин: jovyan
- пароль: jovyan
- порт: 5432
- хост: изнутри контейнера localhost
- база данных: **de**

Вы можете протестировать свой запрос с помощью Python, командной строки и утилиты `psql`, Metabase (URI: `/metabase/`) или DBeaver (URI: `/cloudbeaver/`).
